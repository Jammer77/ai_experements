nohup ./llama.cpp/build/bin/llama-server -m ./llama.cpp/models/codellama-7b-instruct.Q5_K_M.gguf --port 8080 --host 0.0.0.0  > output.log 2>&1 &